# Diagnostic 2
autoplot(bodyfat.lm, which = 2)
# Diagnostic 3
shapiro.test(bodyfat$residuals)
autoplot(bodyfat.lm, which = 3)
autoplot(bodyfat.lm, which = 1)
# Cook's Distance
plot(bodyfat.lm, which = 5, cook.levels = c(4/249))
vif(bodyfat.lm)
library(tidyverse)
library(ggfortify)  # plot glmnet objects using ggplot instead of base R
library(car)  # needed for VIFs
library(bestglm)  # for stepwise methods
library(glmnet)  # for ridge, lasso, and elastic net
set.seed(12345)  # make sure to set your seed when doing cross validation!
setwd("~/School Projects/Stat 330")
env <- read_table("EnvironmentalImpacts.txt") |>
select(-row)
env <- as.data.frame(env)
summary(env)
pairs(env)
library(tidyverse)
library(ggfortify)  # plot glmnet objects using ggplot instead of base R
library(car)  # needed for VIFs
library(bestglm)  # for stepwise methods
library(glmnet)  # for ridge, lasso, and elastic net
library(corrplot)
set.seed(12345)  # make sure to set your seed when doing cross validation!
ggpairs(env)
library(GGally)
ggpairs(env)
ggpairs(env)
corrplot(env)
corrplot(corr(env))
corrplot(cor(env))
corrplot(cor(env))
ggpairs(env)
lm(AAMort ~ .)
lm(AAMort ~ ., data = env)
env.lm <- lm(AAMort ~ ., data = env)
env
env.lm
vif(env.lm)
best_subsets_bic <- bestglm(env,
IC = "BIC",
method = "exhaustive")
# view variables included in the top 10 models
best_subsets_bic$BestModels
# view a summary of the "best" model
summary(best_subsets_bic$BestModel)
base_mod <- lm(AAMort ~ 1, data = env) # Intercept only model (null model, or base model)
full_mod <- lm(AAMort ~ ., data = env) # All predictors in model (besides response)
forw_AIC <- step(base_mod, # starting model for algorithm
direction = "forward",
scope=list(lower= base_mod, upper= full_mod))
## You can also run this code to do forward selection, but
## you can't see the path with this way, to my knowledge.
forw_AIC_2 <- bestglm(env,
IC = "AIC",
method = "forward")
base_mod <- lm(AAMort ~ 1, data = env) # Intercept only model (null model, or base model)
full_mod <- lm(AAMort ~ ., data = env) # All predictors in model (besides response)
back_BIC <- step(base_mod, # starting model for algorithm
direction = "backward",
scope=list(lower= base_mod, upper= full_mod),
k = log(nrow(env)))
base_mod <- lm(AAMort ~ 1, data = env) # Intercept only model (null model, or base model)
full_mod <- lm(AAMort ~ ., data = env) # All predictors in model (besides response)
back_BIC <- step(full_mod, # starting model for algorithm
direction = "backward",
scope=list(lower= base_mod, upper= full_mod),
k = log(nrow(env)))
?step
base_mod <- lm(AAMort ~ 1, data = env) # Intercept only model (null model, or base model)
full_mod <- lm(AAMort ~ ., data = env) # All predictors in model (besides response)
back_BIC <- step(full_mod, # starting model for algorithm
direction = "backward",
scope=list(lower= base_mod, upper= full_mod),
k = log(nrow(env)))
base_mod <- lm(AAMort ~ 1, data = env) # Intercept only model (null model, or base model)
full_mod <- lm(AAMort ~ ., data = env) # All predictors in model (besides response)
back_BIC <- step(base_mod, # starting model for algorithm
direction = "both",
scope=list(lower= base_mod, upper= full_mod),
k = log(nrow(env)))
base_BIC <- step(base_mod, # starting model for algorithm
direction = "both",
scope=list(lower= base_mod, upper= full_mod),
k = log(nrow(env)))
full_BIC <- step(base_mod, # starting model for algorithm
direction = "both",
scope=list(lower= base_mod, upper= full_mod),
k = log(nrow(env)))
env_x <- as.matrix(env[, 1:15]) # predictors
env_y <- env[, 16] # response
# use cross validation to pick the "best" (based on MSE) lambda
env_ridge_cv <- cv.glmnet(x = env_x, # automatically includes a column of ones for the intercept FYI
y = env_y,
type.measure = "mse",
alpha = 0)  # 0 is code for "ridge regression"
# plot (log) lambda vs MSE
autoplot(env_ridge_cv, label = FALSE) +
theme_bw() +
theme(aspect.ratio = 1)
# lambda.min: value of lambda that gives minimum mean cross-validated error
env_ridge_cv$lambda.min
# lambda.1se: value of lambda within 1 standard error of the minimum
# cross-validated error
env_ridge_cv$lambda.1se
coef(env_ridge_cv, s = "lambda.min")
coef(env_ridge_cv, s = "lambda.1se")
env_x <- as.matrix(env[, 1:15]) # predictors
env_y <- env[, 16] # response
# use cross validation to pick the "best" (based on MSE) lambda
env_ridge_cv <- cv.glmnet(x = env_x, # automatically includes a column of ones for the intercept FYI
y = env_y,
type.measure = "mse",
alpha = 1)  # 0 is code for "ridge regression"
# plot (log) lambda vs MSE
autoplot(env_ridge_cv, label = FALSE) +
theme_bw() +
theme(aspect.ratio = 1)
# lambda.min: value of lambda that gives minimum mean cross-validated error
env_ridge_cv$lambda.min
# lambda.1se: value of lambda within 1 standard error of the minimum
# cross-validated error
env_ridge_cv$lambda.1se
coef(env_ridge_cv, s = "lambda.min")
coef(env_ridge_cv, s = "lambda.1se")
env_x <- as.matrix(env[, 1:15]) # predictors
env_y <- env[, 16] # response
# use cross validation to pick the "best" (based on MSE) lambda
env_ridge_cv <- cv.glmnet(x = env_x, # automatically includes a column of ones for the intercept FYI
y = env_y,
type.measure = "mse",
alpha = .5)  # 0 is code for "ridge regression"
# plot (log) lambda vs MSE
autoplot(env_ridge_cv, label = FALSE) +
theme_bw() +
theme(aspect.ratio = 1)
# lambda.min: value of lambda that gives minimum mean cross-validated error
env_ridge_cv$lambda.min
# lambda.1se: value of lambda within 1 standard error of the minimum
# cross-validated error
env_ridge_cv$lambda.1se
coef(env_ridge_cv, s = "lambda.min")
coef(env_ridge_cv, s = "lambda.1se")
final.lm <- lm(AAMort ~ AnnPrecip + MeanJanTemp + School + PctSound + PopPerSqMile + PctNonWhite + log.Nit + log.S02)
final.lm <- lm(AAMort ~ AnnPrecip + MeanJanTemp + School + PctSound + PopPerSqMile + PctNonWhite + log.Nit + log.S02, data = env)
final.lm <- lm(AAMort ~ AnnPrecip + MeanJanTemp + School + PctSound + PopPerSqMile + PctNonWhite + log.Nit + log.SO2, data = env)
final.lm
vif(final.lm)
mean(vif) - 3
mean(vif)
vif <- vif(final.lm)
vif(final.lm)
mean(vif)
mean(vif) - 2
mean(vif)
max(cif)
max(vif)
max(vif)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
collect_metrics(tree_tune)
show_best(tree_tune, metric = 'roc_auc')
best_tune <- tree_tune %>%
select_best("roc_auc")
final_workflow <- rand_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_randforest.csv')
#Stop Parallel
stopCluster(cl)
setwd("~/School Projects/AmazonEmployeeAccess")
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>% #target encoding
step_smote(all_outcomes(), neighbors = 5)
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(mtry = tune(),
trees = 500,
min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model)
tuning_grid <- grid_regular(min_n(),
mtry(c(1, 10)),
levels = 3)
folds <- vfold_cv(df_train, v = 5, repeats = 1)
tree_tune <- tune_grid(my_model,
my_recipe,
folds,
control = control_grid(save_workflow = TRUE),
grid = tuning_grid)
collect_metrics(tree_tune)
show_best(tree_tune, metric = 'roc_auc')
best_tune <- tree_tune %>%
select_best("roc_auc")
final_workflow <- rand_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_randforest.csv')
#Stop Parallel
stopCluster(cl)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(mtry = tune(),
trees = 500,
min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model)
tuning_grid <- grid_regular(min_n(c(2)),
mtry(c(1)),
levels = 1)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(trees = 500,
min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model)
tuning_grid <- grid_regular(min_n(),
levels = 4)
folds <- vfold_cv(df_train, v = 5, repeats = 1)
tree_tune <- tune_grid(my_model,
my_recipe,
folds,
control = control_grid(save_workflow = TRUE),
grid = tuning_grid)
collect_metrics(tree_tune)
show_best(tree_tune, metric = 'roc_auc')
best_tune <- tree_tune %>%
select_best("roc_auc")
final_workflow <- rand_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_randforest.csv')
#Stop Parallel
stopCluster(cl)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(trees = 500,
min_n = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model)
tuning_grid <- grid_regular(min_n(),
levels = 4)
folds <- vfold_cv(df_train, v = 5, repeats = 1)
tree_tune <- tune_grid(my_model,
my_recipe,
folds,
control = control_grid(save_workflow = TRUE),
grid = tuning_grid)
collect_metrics(tree_tune)
show_best(tree_tune, metric = 'roc_auc')
best_tune <- tree_tune %>%
select_best("roc_auc")
final_rand_workflow <- rand_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
logRegModel <- logistic_reg() %>%
set_engine("glm")
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel)
bike_stack <- stacks() %>%
add_candidates(logReg_workflow) %>%
add_candidates(final_rand_workflow)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
library(tidymodels)
library(rsample)
bike_stack <- stacks() %>%
add_candidates(logReg_workflow) %>%
add_candidates(final_rand_workflow)
library(stacks)
bike_stack <- stacks() %>%
add_candidates(logReg_workflow) %>%
add_candidates(final_rand_workflow)
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel) %>%
fit(data = df_train)
bike_stack <- stacks() %>%
add_candidates(logReg_workflow) %>%
add_candidates(final_rand_workflow)
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(trees = 1000,
min_n = 24,
mtry = 1) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_randforest.csv')
#Stop Parallel
stopCluster(cl)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(trees = 1000,
min_n = 24,
mtry = 1) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_randforest.csv')
#Stop Parallel
stopCluster(cl)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
library(doParallel)
library(themis)
detectCores() #How many cores do I have?
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
my_model <- rand_forest(trees = 1000,
min_n = 24,
mtry = 1) %>%
set_engine("ranger") %>%
set_mode("classification")
rand_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = df_train)
amazon_predictions <- predict(rand_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_randforest.csv')
#Stop Parallel
stopCluster(cl)
