colnames(df) <- df[1, ]
df <- df %>%
slice(-1, -2)
df <- df %>%
slice(-1)
colnames(df) <- df[1, ]
df[1, ]
colnames(df) <- df[1, ]
View(df)
df <- vroom('covid_trust_data.csv')
df <- df %>%
slice(-s)
df <- df %>%
slice(-2)
# Cleaning Covid Data
df_clean <- df %>%
filter(finished == 1) %>%
slice(-1) %>%
select(-1, -2, -3, -4, -5, -6, )
# Cleaning Covid Data
df_clean <- df %>%
filter(finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, )
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, )
View(df)
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, )
View(df_clean)
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11)
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13)
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17)
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -LS)
# Cleaning Covid Data
df_clean <- df %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
df <- vroom('covid_trust_data.csv')
# Cleaning Covid Data
df_clean <- df %>%
slice(-2) %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, Q3_7_TEXT
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
df <- vroom('covid_trust_data.csv')
# Cleaning Covid Data
df_clean <- df %>%
slice(-2) %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, -Q3_7_TEXT
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
library(tidyverse)
library(vroom)
df <- vroom('covid_trust_data.csv')
questions <- df[1, ]
questions <- t(questions)
colnames(questions) <- 'questions'
# Cleaning Covid Data
df_clean <- df %>%
slice(-2) %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, -Q3_7_TEXT
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
View(df)
# Cleaning Covid Data
df_clean <- df %>%
slice(-2) %>%
filter(Finished == 1) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, -Q3_7_TEXT,
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
View(df_clean)
# Cleaning Covid Data
df_clean <- df %>%
slice(-2) %>%
filter(Finished !- 0) %>%
# Cleaning Covid Data
df_clean <- df %>%
slice(-2) %>%
filter(Finished != 0) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, -Q3_7_TEXT,
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
View(df_clean)
cor_matrix <- cor(data, use = "complete.obs")
# Cleaning Covid Data
df_clean <- df %>%
slice(-2, -1) %>%
filter(Finished != 0) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, -Q3_7_TEXT,
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS)
cor_matrix <- cor(df_clean, use = "complete.obs")
View(df_clean)
cor_matrix <- cor(as.data.frame(sapply(df_clean, as.numeric)), use = "complete.obs")
summary(df_clean)
skimr::skim(df_clean)
# load any necessary packages here
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  #  Box-Cox transformation
library(onewaytests) # bf.test
library(vroom)
invTranPlot(Distance ~ Speed, data = stop, lambda = c(-1, 0, 1), optimal = TRUE)
# load any necessary packages here
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  #  Box-Cox transformation
library(onewaytests) # bf.test
library(vroom)
stop <- vroom('StoppingDistance.txt')
stop
ggplot(data = stop, aes(x = Speed, y = Distance)) +
geom_point()
ggplot(data = stop, aes(x = Speed, y = Distance)) +
geom_point() +
geom_smooth(method = lm, se = FALSE)
model_no_trans <- lm(Distance ~ Speed, data = stop)
summary(model_no_trans)
stop$residuals = model_no_trans$residuals
stop$fitted.values = model_no_trans$fitted.values
ggplot(data = stop, aes(x = Speed, y = Distance)) +
geom_point()
ggplot(mapping = aes(y = model_no_trans$residuals)) +
geom_boxplot() +
scale_x_discrete() +
labs(title = "Residual Boxplot")
autoplot(model_no_trans, which = 2, ncol = 1, nrow = 1)
autoplot(model_no_trans, which = 3, ncol = 1, nrow = 1)
cd_cont_pos <- function(leverage, level, model) {sqrt(level*length(coef(model))*(1-leverage)/leverage)}
cd_cont_neg <- function(leverage, level, model) {-cd_cont_pos(leverage, level, model)}
cd_threshold <- .5
autoplot(model_no_trans, which = 5) +
stat_function(fun = cd_cont_pos,
args = list(level = cd_threshold, model = model_no_trans),
xlim = c(0, 0.25), lty = 2, colour = "red") +
stat_function(fun = cd_cont_neg,
args = list(level = cd_threshold, model = model_no_trans),
xlim = c(0, 0.25), lty = 2, colour = "red") +
scale_y_continuous(limits = c(-4, 4))
invTranPlot(Distance ~ Speed, data = stop, lambda = c(-1, 0, 1), optimal = TRUE)
ggplot(data = stop, aes(x = log(Speed), y = log(Distance))) +
geom_point()
ggplot(data = stop, aes(x = sqrt(Speed), y = Distance)) +
geom_point()
ggplot(data = stop, aes(x = Speed, y = Distance^2)) +
geom_point()
model_trans <- lm(log(Distance) ~ log(Speed), data = stop)
summary(model_trans)
autoplot(model_trans, which = 1, ncol = 1, nrow = 1)
autoplot(model_trans, which = 2, ncol = 1, nrow = 1)
autoplot(model_trans, which = 3, ncol = 1, nrow = 1)
cd_threshold <- .5
autoplot(model_trans, which = 5) +
stat_function(fun = cd_cont_pos,
args = list(level = cd_threshold, model = model_trans),
xlim = c(0, 0.25), lty = 2, colour = "red") +
stat_function(fun = cd_cont_neg,
args = list(level = cd_threshold, model = model_trans),
xlim = c(0, 0.25), lty = 2, colour = "red") +
scale_y_continuous(limits = c(-4, 4))
# Tip: To get the fitted curve for your transformed model on the original scale, you have to invert the transformation on the response.  Consider the following example.  Suppose the transformed response is Dlog = log(Distance) (this is not necessarily the transformations you should use, it is just an example). If 'fit' is a variable containing the fitted values on the transformed scale (i.e., they are fitted values for Dlog), then the fitted values for Distance would be efit = exp(fit), since exp() is the inverse of log().
x <- seq(0, 40, .1)
y = exp(-1.1 + 1.568*log(x))
ggplot() +
geom_point(data = stop, aes(x = Speed, y = Distance)) +
geom_line(aes(x = x, y = y))
invTranPlot(Distance ~ Speed, data = stop, lambda = c(-1, 0, 1), optimal = TRUE)
ggplot(data = stop, aes(x = log(Speed), y = log(Distance))) +
geom_point()
ggplot(data = stop, aes(x = Speed, y = sqrt(Distance))) +
geom_point()
ggplot(data = stop, aes(x = Speed^2, y = Distance)) +
geom_point()
q()
# load packages here
library(tidyverse)
library(ggfortify)
# load packages here
library(tidyverse)
library(ggfortify)
library(vroom)
wind <- vroom('Windmill.txt')
View(wind)
wind <- vroom('Windmill.txt')
ggplot(wind) +
geom_point(aes(x = RSpd, y = CSpd)) +
geom_smooth(aes(x = RSpd, y = CSpd), se = FALSE)
wind.lm <- lm(CSps ~ RSpd, data = wind)
wind <- vroom('Windmill.txt')
ggplot(wind) +
geom_point(aes(x = RSpd, y = CSpd)) +
geom_smooth(aes(x = RSpd, y = CSpd), se = FALSE)
wind.lm <- lm(CSpd ~ RSpd, data = wind)
wind$residuals <- wind.lm$residuals
wind$fitted.values <- wind.lm$fitted.values
summary(wind.lm)
# When performing step 3, use the format lm(y ~ x, data = wind), where
# y and x are the variable names for the response and predictor
# < your code here >
sqrt(sum(wind.lm$residuals)/(nrow(wind)-2))
sum(wind$RSpd - wind$fitted.values) ^ 2
sum((wind$RSpd - wind$fitted.values)^2)
SE/Sxx
SE <- sqrt(sum(wind.lm$residuals)/(nrow(wind)-2))
Sxx <- sum((wind$RSpd - wind$fitted.values)^2)
SE/Sxx
Sxx <- sum((wind$RSpd - mean(wind$RSpd))^2)
SE/Sxx
SE/sqrt(Sxx)
SE <- sqrt(sum(wind.lm$residuals)/(nrow(wind)-2))
Sxx <- sum((wind$RSpd - mean(wind$RSpd))^2)
SE/sqrt(Sxx)
SE <- sqrt(sum(wind.lm$residuals^2)/(nrow(wind)-2))
Sxx <- sum((wind$RSpd - mean(wind$RSpd))^2)
SE/sqrt(Sxx)
# Uncomment the code below to generate the CI. You must replace my_lm with
# the name of the variable to which you assigned the linear model fit
# If you remove 'par = 2', you will get CIs for the intercept and slope instead
# of just the slope. You can also use par = "RSpd".
CI_slope_99 <- confint(wind.lm, par = 2, level = 0.99)
CI_slope_99
?pt()
2*(1 - pt(38.5, 1114))
# Uncomment the code below to create the CI, again replacing my_lm with the
# appropriate variable name
CI_90_x8 <- predict(wind_lm, newdata = data.frame(RSpd = 8), interval = 'confidence')
# Uncomment the code below to create the CI, again replacing my_lm with the
# appropriate variable name
CI_90_x8 <- predict(wind.lm, newdata = data.frame(RSpd = 8), interval = 'confidence')
CI_90_x8
wind <- vroom('Windmill.txt')
scatter <- ggplot(wind) +
geom_point(aes(x = RSpd, y = CSpd)) +
geom_smooth(aes(x = RSpd, y = CSpd), se = FALSE)
scatter
wind.lm <- lm(CSpd ~ RSpd, data = wind)
wind$residuals <- wind.lm$residuals
wind$fitted.values <- wind.lm$fitted.values
summary(wind.lm)
# When performing step 3, use the format lm(y ~ x, data = wind), where
# y and x are the variable names for the response and predictor
# < your code here >
scatter + geom_smooth(method = 'lm', se = TRUE)
scatter + geom_smooth(aes(x = RSpd, y = CSpd), method = 'lm', se = TRUE)
?predict
predict(wind.lm, data.frame(x = 8))
predict(wind.lm, data.frame(RSpd = 8))
library(tidyverse)
library(vroom)
df <- vroom('covid_trust_data.csv')
# Cleaning Covid Data
df_clean <- df %>%
slice(-2, -1) %>%
filter(Finished != 0) %>%
select(-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13,
-16, -17,
-Q2_4_TEXT, -Q3_7_TEXT,
-opp, -qpmid, -RISN, -rid, -V, -cintid, -ProjectToken, -viga, -gc, -term, -Q_TotalDuration, -race, -LS) %>%
rename(age = Q1,
gender = Q2,
race = Q3,
income = Q4,
house_size = Q5,
degree = Q9,
marital_status = Q10,
children = Q11,
political_view = Q12,
living_area = Q14
)
write_csv(df_clean, 'covid_clean.csv')
View(df_clean)
library(tidyverse)
library(vroom)
library(ggfortify)
library(car)
df.lm <- lm(dex ~ age, data = df)
library(tidyverse)
library(vroom)
library(ggfortify)
library(car)
df <- vroom('dexterity.txt')
ggplot(data = df) +
geom_histogram(aes(x = age), binwidth = 1)
ggplot(data = df) +
geom_boxplot(aes(x = age))
ggplot(data = df) +
geom_histogram(aes(x = dex))
ggplot(data = df) +
geom_boxplot(aes(x = dex))
ggplot(data = df) +
geom_point(aes(x = age, y = dex))
df.lm <- lm(dex ~ age, data = df)
autoplot(df.lm, which = 1)
autoplot(df.lm, which = 2)
autoplot(df.lm, which = 3)
cd_cont_pos <- function(leverage, level, model) {sqrt(level*length(coef(model))*(1-leverage)/leverage)}
cd_cont_neg <- function(leverage, level, model) {-cd_cont_pos(leverage, level, model)}
cd_threshold <- .5
autoplot(df.lm, which = 5) +
stat_function(fun = cd_cont_pos,
args = list(level = cd_threshold, model = df.lm),
xlim = c(0, 0.25), lty = 2, colour = "red") +
stat_function(fun = cd_cont_neg,
args = list(level = cd_threshold, model = df.lm),
xlim = c(0, 0.25), lty = 2, colour = "red") +
scale_y_continuous(limits = c(-4, 4))
ggplot(data = df) +
geom_point(aes(x = age, y = dex)) +
geom_smooth(aes(x = age, y = dex), method = 'lm', se = FALSE)
ggplot(data = df[-2, ]) +
geom_point(aes(x = age, y = dex)) +
geom_smooth(aes(x = age, y = dex), method = 'lm', se = FALSE)
invTranPlot(dex ~ age, data = df, lambda = c(-1, 0, 1), optimal = TRUE)
summary(df.lm)
# <your code here>
# <your code here>
cor(df$dex, df$age)
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
setwd("~/Desktop/School Projects/AmazonEmployeeAccess")
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
sample <- vroom('sampleSubmission.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
# step_dummy(all_nominal_predictors()) #dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
View(baked)
logRegModel <- logistic_reg(mixture = tune(),
penalty = tune()) %>%
set_engine("glmnet")
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel) %>%
fit(data = df_train)
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5)
folds <- vfold_cv(df_train, v = 5, repeats = 1)
cv_results <- logReg_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid)
best_tune <- cv_results %>%
select_best("roc_auc")
View(best_tune)
final_workflow <- logReg_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train_clean)
final_workflow <- logReg_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_2.csv')
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
sample <- vroom('sampleSubmission.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
# step_dummy(all_nominal_predictors()) #dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
logRegModel <- logistic_reg(mixture = tune(),
penalty = tune()) %>%
set_engine("glmnet")
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel) %>%
fit(data = df_train)
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5)
folds <- vfold_cv(df_train, v = 5, repeats = 1)
cv_results <- logReg_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid)
best_tune <- cv_results %>%
select_best("roc_auc")
final_workflow <- logReg_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_3.csv')
library(tidymodels)
library(tidyverse)
library(embed)
library(vroom)
df_train <- vroom('train.csv') %>%
mutate(ACTION = as.factor(ACTION))
df_test <- vroom('test.csv')
sample <- vroom('sampleSubmission.csv')
my_recipe <- recipe(ACTION ~ ., data=df_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
# step_dummy(all_nominal_predictors()) #dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
prep <- prep(my_recipe)
baked <- bake(prep, new_data = NULL)
logRegModel <- logistic_reg(mixture = tune(),
penalty = tune()) %>%
set_engine("glmnet")
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel) %>%
fit(data = df_train)
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5)
folds <- vfold_cv(df_train, v = 5, repeats = 1)
cv_results <- logReg_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc, f_meas, sens, recall, spec,
precision, accuracy))
best_tune <- cv_results %>%
select_best("roc_auc")
final_workflow <- logReg_workflow %>%
finalize_workflow(best_tune) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_3.csv')
View(cv_results)
cv_results <- logReg_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
View(cv_results)
best_tune(cv_results)
collect_metrics(cv_results)
logRegModel <- logistic_reg(mixture = 0,
penalty = 0) %>%
set_engine("glmnet")
final_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel) %>%
fit(data = df_train)
amazon_predictions <- predict(final_workflow,
new_data = df_test,
type = 'prob')
submission <- amazon_predictions %>%
bind_cols(df_test) %>%
select(id, .pred_1) %>%
rename(Action = .pred_1)
write_csv(submission, 'submission_3.csv')
collect_metrics(cv_results)
met <- collect_metrics(cv_results)
View(met)
